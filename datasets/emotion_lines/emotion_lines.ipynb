{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = Path(\"./datasets\")\n",
    "dev_path = datasets_path / \"emotion_lines\" / \"friends_dev.json\"\n",
    "test_path = datasets_path / \"emotion_lines\" / \"friends_test.json\"\n",
    "train_path = datasets_path / \"emotion_lines\" / \"friends_train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path: Path):\n",
    "    # read json file\n",
    "    data = json.loads(path.read_bytes())\n",
    "\n",
    "    # extract sentences and labels\n",
    "    sentences_list: List[List[str]] = []\n",
    "    labels_list: List[List[str]] = []\n",
    "    for dialog in data:\n",
    "        sentences: List[str] = []\n",
    "        labels: List[str] = []\n",
    "        for utterance in dialog:\n",
    "            sentences.append(f\"{utterance['speaker']}: {utterance['utterance']}\")\n",
    "            labels.append(utterance[\"emotion\"])\n",
    "\n",
    "        sentences_list.append(sentences)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame({\"sentences\": sentences_list, \"labels\": labels_list})\n",
    "\n",
    "    # save dataframe\n",
    "    df.to_parquet(path.with_suffix(\".parquet\"))\n",
    "\n",
    "    # unique labels\n",
    "    unique_labels = set()\n",
    "    for labels in labels_list:\n",
    "        unique_labels.update(labels)\n",
    "    return unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = create_dataset(dev_path)\n",
    "l2 = create_dataset(test_path)\n",
    "l3 = create_dataset(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = l1.union(l2).union(l3)\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "dev_df = pd.read_parquet(dev_path.with_suffix(\".parquet\"))\n",
    "test_df = pd.read_parquet(test_path.with_suffix(\".parquet\"))\n",
    "train_df = pd.read_parquet(train_path.with_suffix(\".parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to count the number of rows that contain the label \"non-neutral\"\n",
    "\n",
    "# count the number of rows that contain the label \"non-neutral\"\n",
    "print(dev_df[\"labels\"].apply(lambda x: \"non-neutral\" in x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sent-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
